{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('../../').resolve()))\n",
    "from utils.tools import save_multichannel_preview\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from torchvision import transforms\n",
    "from scifAI.dl.dataset import DatasetGenerator\n",
    "from scifAI.dl.utils import get_statistics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd0725d4a70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_107508/233255928.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n",
    "metadata.set.unique()\n",
    "indx = metadata.condition.isin([\"-SEA\",\"+SEA\"])\n",
    "metadata = metadata.loc[indx, :].reset_index(drop = True )\n",
    "set_of_interesting_classes = ['B_cell',  'T_cell', \n",
    "                        'T_cell_with_signaling',\n",
    "                        'T_cell_with_B_cell_fragments',\n",
    "                        'B_T_cell_in_one_layer',\n",
    "                        'Synapses_without_signaling', \n",
    "                        'Synapses_with_signaling',\n",
    "                        'No_cell_cell_interaction', \n",
    "                        'Multiplets'] \n",
    "\n",
    "indx = metadata.set.isin([ \"train\", \"validation\",\"test\" ])\n",
    "indx = indx & metadata.label.isin(set_of_interesting_classes)\n",
    "\n",
    "train_index = metadata[\"set\"] == \"train\"\n",
    "train_index = train_index & metadata.label.isin(set_of_interesting_classes)\n",
    "train_index = train_index[train_index].index\n",
    "\n",
    "validation_index = metadata[\"set\"] == \"validation\"\n",
    "validation_index = validation_index & metadata.label.isin(set_of_interesting_classes)\n",
    "validation_index = validation_index[validation_index].index\n",
    "\n",
    "test_index = metadata[\"set\"] == \"test\"\n",
    "test_index = test_index & metadata.label.isin(set_of_interesting_classes)\n",
    "test_index = test_index[test_index].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [05:28<00:00, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0., 0., 0., 0., 0.]), 'p01': tensor([0., 0., 0., 0., 0.]), 'p05': tensor([0., 0., 0., 0., 0.]), 'p25': tensor([0.1943, 0.0128, 0.0092, 0.0129, 0.0094]), 'p50': tensor([0.1950, 0.0163, 0.0136, 0.0200, 0.0096]), 'p75': tensor([0.1956, 0.0205, 0.0193, 0.0256, 0.0097]), 'p95': tensor([0.1962, 0.0347, 0.0295, 0.0346, 0.0101]), 'p99': tensor([0.1989, 0.0587, 0.0474, 0.0478, 0.0107]), 'max': tensor([0.3295, 0.7863, 0.4366, 0.3361, 0.1161]), 'mean': tensor([0.1721, 0.0172, 0.0148, 0.0198, 0.0085]), 'std': tensor([0.0629, 0.0141, 0.0109, 0.0122, 0.0031])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metadata[\"set\"].unique()\n",
    "label_map = dict()\n",
    "for i, cl in enumerate(set_of_interesting_classes):\n",
    "    label_map[cl] = i\n",
    "\n",
    "label_map['-1'] = -1\n",
    "label_map[-1] = -1\n",
    "\n",
    "\n",
    "channels = {\n",
    "     \"Ch1\": (\"Greys\", \"BF\"),  \n",
    "     \"Ch2\": (\"Greens\", \"Antibody\"),\n",
    "     \"Ch3\": (\"Reds\", \"CD18\"),\n",
    "     \"Ch4\": (\"Oranges\", \"F-Actin\"),\n",
    "     \"Ch6\": (\"RdPu\", \"MHCII\"),\n",
    "     \"Ch7\": (\"Purples\", \"CD3/CD4\"),\n",
    "     \"Ch11\": (\"Blues\", \"P-CD3zeta\"),\n",
    "     \"Ch12\": (\"Greens\", \"Live-Dead\")\n",
    " }\n",
    "\n",
    "selected_channels = [0,3,4,5,6]\n",
    "model_dir = \"models\"\n",
    "log_dir = \"logs\"\n",
    "scaling_factor = 4095.\n",
    "reshape_size = 256\n",
    "train_transform = [\n",
    "         transforms.RandomVerticalFlip(),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(45)\n",
    "        ]\n",
    "test_transform = [ ]\n",
    "\n",
    "train_dataset = DatasetGenerator(metadata=metadata.loc[train_index,:],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=transforms.Compose(train_transform))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "statistics = get_statistics(train_loader, selected_channels=selected_channels)\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    def __init__(self, min_in , max_in, min_out, max_out):\n",
    "        self.min_in = min_in.reshape(-1,1,1)\n",
    "        self.max_in = max_in.reshape(-1,1,1)\n",
    "        self.min_out = min_out\n",
    "        self.max_out = max_out\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \n",
    "        tensor_ = (tensor - self.min_in)/(self.max_in - self.min_in)\n",
    "        tensor_ = tensor_*(self.max_out - self.min_out) + self.min_out\n",
    "        tensor_[tensor_<self.min_out]= self.min_out\n",
    "        tensor_[tensor_>self.max_out]= self.max_out\n",
    "        return tensor_\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(min_out={0}, max_out={1})'.format(self.min_out, self.max_out)\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "        transforms.RandomResizedCrop(reshape_size, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        AddGaussianNoise(mean=0., std=0.01),\n",
    "])\n",
    "\n",
    "validation_transform =  transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        AddGaussianNoise(mean=0., std=0.01),\n",
    "])\n",
    "\n",
    "test_transform =  transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "])\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "train_dataset = DatasetGenerator(metadata=metadata.loc[train_index, :],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=train_transform)\n",
    "\n",
    "valid_dataset = DatasetGenerator(metadata=metadata.loc[validation_index, :],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=validation_transform)\n",
    "\n",
    "# Convert to FastAI DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map = {\n",
    "     \"Ch1\": (\"Greys\", \"BF\"),  \n",
    "     \"Ch2\": (\"Greens\", \"Antibody\"),\n",
    "     \"Ch3\": (\"Reds\", \"CD18\"),\n",
    "     \"Ch4\": (\"Oranges\", \"F-Actin\"),\n",
    "     \"Ch6\": (\"RdPu\", \"MHCII\"),\n",
    "     \"Ch7\": (\"Purples\", \"CD3/CD4\"),\n",
    "     \"Ch11\": (\"Blues\", \"P-CD3zeta\"),\n",
    "     \"Ch12\": (\"Greens\", \"Live-Dead\")\n",
    " }\n",
    "\n",
    "save_multichannel_preview(train_dl, n_samples=10, save_path=\"train_multichannel_preview.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
