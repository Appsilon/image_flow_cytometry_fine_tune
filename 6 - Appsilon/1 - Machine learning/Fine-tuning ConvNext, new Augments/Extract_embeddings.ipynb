{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2076836/1582801263.py:27: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cuda memory before model initialization: \n",
      "Device 0:\n",
      "  Allocated Memory: 772.33 MB\n",
      "  Reserved Memory: 1658.00 MB\n",
      "  Free Memory: 13259.69 MB\n",
      "  Total Memory: 14917.69 MB\n",
      "Initializing datasets...\n",
      "Datasets initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import lightning.pytorch as pl\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('../../').resolve()))\n",
    "from utils import convnext, tools\n",
    "from fastai.vision.all import *\n",
    "from experiment_specific_utils import data_module, transforms\n",
    "\n",
    "# %%\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# %%\n",
    "metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n",
    "metadata\n",
    "\n",
    "# %%\n",
    "metadata.set.unique()\n",
    "\n",
    "# %%\n",
    "indx = metadata.condition.isin([\"-SEA\",\"+SEA\"])\n",
    "metadata = metadata.loc[indx, :].reset_index(drop = True )\n",
    "\n",
    "# %%\n",
    "set_of_interesting_classes = ['B_cell',  'T_cell', \n",
    "                        'T_cell_with_signaling',\n",
    "                        'T_cell_with_B_cell_fragments',\n",
    "                        'B_T_cell_in_one_layer',\n",
    "                        'Synapses_without_signaling', \n",
    "                        'Synapses_with_signaling',\n",
    "                        'No_cell_cell_interaction', \n",
    "                        'Multiplets'] \n",
    "\n",
    "indx = metadata.set.isin([ \"train\", \"validation\",\"test\" ])\n",
    "indx = indx & metadata.label.isin(set_of_interesting_classes)\n",
    "\n",
    "train_index = metadata[\"set\"] == \"train\"\n",
    "train_index = train_index & metadata.label.isin(set_of_interesting_classes)\n",
    "train_index = train_index[train_index].index\n",
    "\n",
    "validation_index = metadata[\"set\"] == \"validation\"\n",
    "validation_index = validation_index & metadata.label.isin(set_of_interesting_classes)\n",
    "validation_index = validation_index[validation_index].index\n",
    "\n",
    "test_index = metadata[\"set\"] == \"test\"\n",
    "test_index = test_index & metadata.label.isin(set_of_interesting_classes)\n",
    "test_index = test_index[test_index].index\n",
    "\n",
    "# %%\n",
    "metadata[\"set\"].unique()\n",
    "\n",
    "# %%\n",
    "label_map = dict()\n",
    "for i, cl in enumerate(set_of_interesting_classes):\n",
    "    label_map[cl] = i\n",
    "\n",
    "label_map['-1'] = -1\n",
    "label_map[-1] = -1\n",
    "\n",
    "# %%\n",
    "channels = {\n",
    "     \"Ch1\": (\"Greys\", \"BF\"),  \n",
    "     \"Ch2\": (\"Greens\", \"Antibody\"),\n",
    "     \"Ch3\": (\"Reds\", \"CD18\"),\n",
    "     \"Ch4\": (\"Oranges\", \"F-Actin\"),\n",
    "     \"Ch6\": (\"RdPu\", \"MHCII\"),\n",
    "     \"Ch7\": (\"Purples\", \"CD3/CD4\"),\n",
    "     \"Ch11\": (\"Blues\", \"P-CD3zeta\"),\n",
    "     \"Ch12\": (\"Greens\", \"Live-Dead\")\n",
    " }\n",
    "\n",
    "# %%\n",
    "selected_channels = [0,3,4,5,6]\n",
    "model_dir = \"models\"\n",
    "log_dir = \"logs\"\n",
    "scaling_factor = 4095.\n",
    "reshape_size = 256\n",
    "train_transform = transforms.train_transform_fit_image(reshape_size, include_normalization = True)\n",
    "test_val_transform = transforms.test_val_transform_fit_image(reshape_size)\n",
    "\n",
    "# %%\n",
    "lr=0.0004\n",
    "batch_size=32\n",
    "max_epochs=50\n",
    "\n",
    "# %%\n",
    "print(\"Available cuda memory before model initialization: \")\n",
    "tools.print_cuda_memory()\n",
    "\n",
    "synapse_formation_module = data_module.SynapseFormationDataModule(metadata, train_index, validation_index, test_index, label_map, selected_channels, train_transform,\n",
    "                                                test_val_transform, test_val_transform, batch_size, reshape_size)\n",
    "\n",
    "synapse_formation_module.setup(stage='fit')\n",
    "train_loader = synapse_formation_module.train_dataloader()\n",
    "val_loader = synapse_formation_module.val_dataloader()\n",
    "model = convnext.ConvnextModel(num_classes=len(set_of_interesting_classes), in_chans=len(selected_channels), steps_per_epoch=len(train_loader), learning_rate=lr, max_epochs=max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2076836/1965282011.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/home/jedrzej/projects/image_flow_cytometry_fine_tune/6 - Appsilon/1 - Machine learning/Fine-tuning ConvNext, new Augments/.neptune/IM-58/IM-58/checkpoints/epoch=49-step=4600.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvnextModel(\n",
       "  (model): ConvNeXt(\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(5, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ConvNeXtStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "            (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "            (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (6): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (7): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (8): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (9): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (10): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (11): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (12): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (13): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (14): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (15): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (16): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (17): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (18): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (19): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (20): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (21): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (22): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (23): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (24): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (25): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (26): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "            (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ConvNeXtStage(\n",
       "        (downsample): Sequential(\n",
       "          (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "            (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_pre): Identity()\n",
       "    (head): NormMlpClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "      (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (pre_logits): Identity()\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (fc): Linear(in_features=1024, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (train_acc): MulticlassAccuracy()\n",
       "  (val_acc): MulticlassAccuracy()\n",
       "  (f1_score): MulticlassF1Score()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "def extract_embeddings(nn_model, data_loader):\n",
    "    nn_model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs, batch_labels = batch\n",
    "            inputs = inputs.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            batch_embeddings = nn_model.model.forward_features(inputs)\n",
    "            if batch_embeddings.dim() == 4:\n",
    "                batch_embeddings = nn_model.model.head.global_pool(batch_embeddings)\n",
    "                batch_embeddings = nn_model.model.head.norm(batch_embeddings)\n",
    "                batch_embeddings = nn_model.model.head.flatten(batch_embeddings)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            labels.append(batch_labels.cpu().numpy())\n",
    "    return np.vstack(embeddings), np.hstack(labels)\n",
    "test_loader = synapse_formation_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(\"cuda\")\n",
    "a = extract_embeddings(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels = a\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "embeddings_df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormMlpClassifierHead(\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "  (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (pre_logits): Identity()\n",
       "  (drop): Dropout(p=0, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.805928</td>\n",
       "      <td>0.157662</td>\n",
       "      <td>0.576173</td>\n",
       "      <td>-1.388507</td>\n",
       "      <td>-0.532080</td>\n",
       "      <td>-0.541615</td>\n",
       "      <td>0.370675</td>\n",
       "      <td>-0.245025</td>\n",
       "      <td>-0.098967</td>\n",
       "      <td>-0.168570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.135303</td>\n",
       "      <td>-0.742776</td>\n",
       "      <td>-0.300688</td>\n",
       "      <td>0.490303</td>\n",
       "      <td>-0.122583</td>\n",
       "      <td>-0.406470</td>\n",
       "      <td>1.017134</td>\n",
       "      <td>0.422110</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.231208</td>\n",
       "      <td>0.220913</td>\n",
       "      <td>0.069007</td>\n",
       "      <td>-1.778880</td>\n",
       "      <td>-0.581510</td>\n",
       "      <td>-0.988908</td>\n",
       "      <td>0.896636</td>\n",
       "      <td>-0.943685</td>\n",
       "      <td>0.320128</td>\n",
       "      <td>0.364289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653211</td>\n",
       "      <td>-0.412481</td>\n",
       "      <td>-0.439893</td>\n",
       "      <td>-0.611772</td>\n",
       "      <td>0.721221</td>\n",
       "      <td>-0.370233</td>\n",
       "      <td>-0.130313</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>0.189012</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.789709</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>-0.269214</td>\n",
       "      <td>0.156545</td>\n",
       "      <td>0.484728</td>\n",
       "      <td>0.968309</td>\n",
       "      <td>-1.113086</td>\n",
       "      <td>-1.027873</td>\n",
       "      <td>-0.020747</td>\n",
       "      <td>0.834888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338997</td>\n",
       "      <td>0.428002</td>\n",
       "      <td>0.894622</td>\n",
       "      <td>-0.018873</td>\n",
       "      <td>0.605495</td>\n",
       "      <td>-0.928183</td>\n",
       "      <td>-0.155133</td>\n",
       "      <td>-0.315386</td>\n",
       "      <td>-0.502222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428416</td>\n",
       "      <td>0.991594</td>\n",
       "      <td>1.584693</td>\n",
       "      <td>1.542397</td>\n",
       "      <td>0.868679</td>\n",
       "      <td>0.373881</td>\n",
       "      <td>-0.386599</td>\n",
       "      <td>0.750486</td>\n",
       "      <td>-0.251176</td>\n",
       "      <td>-0.739195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376323</td>\n",
       "      <td>-0.744421</td>\n",
       "      <td>0.597434</td>\n",
       "      <td>-0.288840</td>\n",
       "      <td>-1.622254</td>\n",
       "      <td>0.041113</td>\n",
       "      <td>-0.150973</td>\n",
       "      <td>-1.568519</td>\n",
       "      <td>-0.433807</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.588597</td>\n",
       "      <td>-0.093517</td>\n",
       "      <td>-0.193951</td>\n",
       "      <td>-1.536536</td>\n",
       "      <td>-0.823488</td>\n",
       "      <td>-0.815557</td>\n",
       "      <td>0.410563</td>\n",
       "      <td>-0.760440</td>\n",
       "      <td>0.172343</td>\n",
       "      <td>0.493134</td>\n",
       "      <td>...</td>\n",
       "      <td>1.359203</td>\n",
       "      <td>-0.409685</td>\n",
       "      <td>-0.396260</td>\n",
       "      <td>-0.475106</td>\n",
       "      <td>0.795944</td>\n",
       "      <td>-0.686296</td>\n",
       "      <td>0.292118</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.322555</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0.602211</td>\n",
       "      <td>-0.651645</td>\n",
       "      <td>0.424338</td>\n",
       "      <td>-0.409297</td>\n",
       "      <td>0.236796</td>\n",
       "      <td>0.232826</td>\n",
       "      <td>-0.759870</td>\n",
       "      <td>-0.214824</td>\n",
       "      <td>0.058799</td>\n",
       "      <td>-0.242292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482324</td>\n",
       "      <td>0.198505</td>\n",
       "      <td>1.190233</td>\n",
       "      <td>0.132923</td>\n",
       "      <td>-0.917505</td>\n",
       "      <td>-0.232920</td>\n",
       "      <td>-0.175433</td>\n",
       "      <td>-0.690463</td>\n",
       "      <td>1.159616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>0.618455</td>\n",
       "      <td>0.636236</td>\n",
       "      <td>-0.199383</td>\n",
       "      <td>-0.415231</td>\n",
       "      <td>0.032799</td>\n",
       "      <td>0.348827</td>\n",
       "      <td>-0.299616</td>\n",
       "      <td>1.382883</td>\n",
       "      <td>-0.527806</td>\n",
       "      <td>0.349540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434015</td>\n",
       "      <td>0.590330</td>\n",
       "      <td>-0.245880</td>\n",
       "      <td>0.366202</td>\n",
       "      <td>0.125456</td>\n",
       "      <td>0.212768</td>\n",
       "      <td>0.664973</td>\n",
       "      <td>1.908127</td>\n",
       "      <td>1.251918</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>-0.395108</td>\n",
       "      <td>-1.858959</td>\n",
       "      <td>0.874642</td>\n",
       "      <td>0.097085</td>\n",
       "      <td>-0.252257</td>\n",
       "      <td>1.345946</td>\n",
       "      <td>-0.161412</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>-1.262412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261453</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>-2.219505</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>0.185377</td>\n",
       "      <td>-0.446499</td>\n",
       "      <td>1.517568</td>\n",
       "      <td>0.045162</td>\n",
       "      <td>-0.524976</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>1.171908</td>\n",
       "      <td>-0.349277</td>\n",
       "      <td>-0.423955</td>\n",
       "      <td>-0.416062</td>\n",
       "      <td>-1.117623</td>\n",
       "      <td>-0.213249</td>\n",
       "      <td>-0.573584</td>\n",
       "      <td>-0.241543</td>\n",
       "      <td>1.125976</td>\n",
       "      <td>-0.368923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755614</td>\n",
       "      <td>-0.526437</td>\n",
       "      <td>0.245659</td>\n",
       "      <td>-1.298746</td>\n",
       "      <td>-0.052835</td>\n",
       "      <td>-0.404227</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>-0.441783</td>\n",
       "      <td>0.182905</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>0.616642</td>\n",
       "      <td>1.281863</td>\n",
       "      <td>-0.334229</td>\n",
       "      <td>-0.193792</td>\n",
       "      <td>0.012934</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>-0.229114</td>\n",
       "      <td>1.692958</td>\n",
       "      <td>-0.886451</td>\n",
       "      <td>0.221190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085492</td>\n",
       "      <td>0.465645</td>\n",
       "      <td>-0.228680</td>\n",
       "      <td>0.078756</td>\n",
       "      <td>-0.120862</td>\n",
       "      <td>0.725209</td>\n",
       "      <td>0.184880</td>\n",
       "      <td>1.796772</td>\n",
       "      <td>0.747443</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.805928  0.157662  0.576173 -1.388507 -0.532080 -0.541615  0.370675   \n",
       "1    -1.231208  0.220913  0.069007 -1.778880 -0.581510 -0.988908  0.896636   \n",
       "2    -0.789709  0.021753 -0.269214  0.156545  0.484728  0.968309 -1.113086   \n",
       "3     0.428416  0.991594  1.584693  1.542397  0.868679  0.373881 -0.386599   \n",
       "4    -1.588597 -0.093517 -0.193951 -1.536536 -0.823488 -0.815557  0.410563   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1562  0.602211 -0.651645  0.424338 -0.409297  0.236796  0.232826 -0.759870   \n",
       "1563  0.618455  0.636236 -0.199383 -0.415231  0.032799  0.348827 -0.299616   \n",
       "1564 -0.395108 -1.858959  0.874642  0.097085 -0.252257  1.345946 -0.161412   \n",
       "1565  1.171908 -0.349277 -0.423955 -0.416062 -1.117623 -0.213249 -0.573584   \n",
       "1566  0.616642  1.281863 -0.334229 -0.193792  0.012934 -0.167785 -0.229114   \n",
       "\n",
       "             7         8         9  ...      1015      1016      1017  \\\n",
       "0    -0.245025 -0.098967 -0.168570  ...  0.526800  0.135303 -0.742776   \n",
       "1    -0.943685  0.320128  0.364289  ...  0.653211 -0.412481 -0.439893   \n",
       "2    -1.027873 -0.020747  0.834888  ...  0.338997  0.428002  0.894622   \n",
       "3     0.750486 -0.251176 -0.739195  ...  0.376323 -0.744421  0.597434   \n",
       "4    -0.760440  0.172343  0.493134  ...  1.359203 -0.409685 -0.396260   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1562 -0.214824  0.058799 -0.242292  ... -0.482324  0.198505  1.190233   \n",
       "1563  1.382883 -0.527806  0.349540  ...  0.434015  0.590330 -0.245880   \n",
       "1564  0.073800  0.019879 -1.262412  ... -0.261453  0.560484 -2.219505   \n",
       "1565 -0.241543  1.125976 -0.368923  ... -0.755614 -0.526437  0.245659   \n",
       "1566  1.692958 -0.886451  0.221190  ...  0.085492  0.465645 -0.228680   \n",
       "\n",
       "          1018      1019      1020      1021      1022      1023  label  \n",
       "0    -0.300688  0.490303 -0.122583 -0.406470  1.017134  0.422110      7  \n",
       "1    -0.611772  0.721221 -0.370233 -0.130313  0.814041  0.189012      7  \n",
       "2    -0.018873  0.605495 -0.928183 -0.155133 -0.315386 -0.502222      1  \n",
       "3    -0.288840 -1.622254  0.041113 -0.150973 -1.568519 -0.433807      3  \n",
       "4    -0.475106  0.795944 -0.686296  0.292118  0.829582  0.322555      7  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "1562  0.132923 -0.917505 -0.232920 -0.175433 -0.690463  1.159616      0  \n",
       "1563  0.366202  0.125456  0.212768  0.664973  1.908127  1.251918      6  \n",
       "1564 -0.059975  0.185377 -0.446499  1.517568  0.045162 -0.524976      4  \n",
       "1565 -1.298746 -0.052835 -0.404227  0.097928 -0.441783  0.182905      8  \n",
       "1566  0.078756 -0.120862  0.725209  0.184880  1.796772  0.747443      5  \n",
       "\n",
       "[1567 rows x 1025 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.columns = [str(col) for col in embeddings_df.columns]\n",
    "embeddings_df.to_parquet(\"test_embeddings_labels_convnext.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
