{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path('../../').resolve()))\n",
    "from utils.tools import save_multichannel_preview\n",
    "import pandas as pd\n",
    "from fastai.vision.all import *\n",
    "from torchvision import transforms\n",
    "from scifAI.dl.dataset import DatasetGenerator\n",
    "from scifAI.dl.utils import get_statistics\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_107508/233255928.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/home/jedrzej/projects/image_flow_cytometry_fine_tune/data/jedrzej/metadata_subset.csv.gz\")\n",
    "metadata.set.unique()\n",
    "indx = metadata.condition.isin([\"-SEA\",\"+SEA\"])\n",
    "metadata = metadata.loc[indx, :].reset_index(drop = True )\n",
    "set_of_interesting_classes = ['B_cell',  'T_cell', \n",
    "                        'T_cell_with_signaling',\n",
    "                        'T_cell_with_B_cell_fragments',\n",
    "                        'B_T_cell_in_one_layer',\n",
    "                        'Synapses_without_signaling', \n",
    "                        'Synapses_with_signaling',\n",
    "                        'No_cell_cell_interaction', \n",
    "                        'Multiplets'] \n",
    "\n",
    "indx = metadata.set.isin([ \"train\", \"validation\",\"test\" ])\n",
    "indx = indx & metadata.label.isin(set_of_interesting_classes)\n",
    "\n",
    "train_index = metadata[\"set\"] == \"train\"\n",
    "train_index = train_index & metadata.label.isin(set_of_interesting_classes)\n",
    "train_index = train_index[train_index].index\n",
    "\n",
    "validation_index = metadata[\"set\"] == \"validation\"\n",
    "validation_index = validation_index & metadata.label.isin(set_of_interesting_classes)\n",
    "validation_index = validation_index[validation_index].index\n",
    "\n",
    "test_index = metadata[\"set\"] == \"test\"\n",
    "test_index = test_index & metadata.label.isin(set_of_interesting_classes)\n",
    "test_index = test_index[test_index].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [05:28<00:00, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics used: {'min': tensor([0., 0., 0., 0., 0.]), 'p01': tensor([0., 0., 0., 0., 0.]), 'p05': tensor([0., 0., 0., 0., 0.]), 'p25': tensor([0.1943, 0.0128, 0.0092, 0.0129, 0.0094]), 'p50': tensor([0.1950, 0.0163, 0.0136, 0.0200, 0.0096]), 'p75': tensor([0.1956, 0.0205, 0.0193, 0.0256, 0.0097]), 'p95': tensor([0.1962, 0.0347, 0.0295, 0.0346, 0.0101]), 'p99': tensor([0.1989, 0.0587, 0.0474, 0.0478, 0.0107]), 'max': tensor([0.3295, 0.7863, 0.4366, 0.3361, 0.1161]), 'mean': tensor([0.1721, 0.0172, 0.0148, 0.0198, 0.0085]), 'std': tensor([0.0629, 0.0141, 0.0109, 0.0122, 0.0031])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metadata[\"set\"].unique()\n",
    "label_map = dict()\n",
    "for i, cl in enumerate(set_of_interesting_classes):\n",
    "    label_map[cl] = i\n",
    "\n",
    "label_map['-1'] = -1\n",
    "label_map[-1] = -1\n",
    "\n",
    "\n",
    "channels = {\n",
    "     \"Ch1\": (\"Greys\", \"BF\"),  \n",
    "     \"Ch2\": (\"Greens\", \"Antibody\"),\n",
    "     \"Ch3\": (\"Reds\", \"CD18\"),\n",
    "     \"Ch4\": (\"Oranges\", \"F-Actin\"),\n",
    "     \"Ch6\": (\"RdPu\", \"MHCII\"),\n",
    "     \"Ch7\": (\"Purples\", \"CD3/CD4\"),\n",
    "     \"Ch11\": (\"Blues\", \"P-CD3zeta\"),\n",
    "     \"Ch12\": (\"Greens\", \"Live-Dead\")\n",
    " }\n",
    "\n",
    "selected_channels = [0,3,4,5,6]\n",
    "model_dir = \"models\"\n",
    "log_dir = \"logs\"\n",
    "scaling_factor = 4095.\n",
    "reshape_size = 256\n",
    "train_transform = [\n",
    "         transforms.RandomVerticalFlip(),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(45)\n",
    "        ]\n",
    "test_transform = [ ]\n",
    "\n",
    "train_dataset = DatasetGenerator(metadata=metadata.loc[train_index,:],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=transforms.Compose(train_transform))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "statistics = get_statistics(train_loader, selected_channels=selected_channels)\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    def __init__(self, min_in , max_in, min_out, max_out):\n",
    "        self.min_in = min_in.reshape(-1,1,1)\n",
    "        self.max_in = max_in.reshape(-1,1,1)\n",
    "        self.min_out = min_out\n",
    "        self.max_out = max_out\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \n",
    "        tensor_ = (tensor - self.min_in)/(self.max_in - self.min_in)\n",
    "        tensor_ = tensor_*(self.max_out - self.min_out) + self.min_out\n",
    "        tensor_[tensor_<self.min_out]= self.min_out\n",
    "        tensor_[tensor_>self.max_out]= self.max_out\n",
    "        return tensor_\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(min_out={0}, max_out={1})'.format(self.min_out, self.max_out)\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "        transforms.RandomResizedCrop(reshape_size, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        AddGaussianNoise(mean=0., std=0.01),\n",
    "])\n",
    "\n",
    "validation_transform =  transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        AddGaussianNoise(mean=0., std=0.01),\n",
    "])\n",
    "\n",
    "test_transform =  transforms.Compose([ \n",
    "        MinMaxScaler(           min_in =  statistics[\"p05\"] , \n",
    "                                max_in =  statistics[\"p95\"] , \n",
    "                                min_out =  0. , \n",
    "                                max_out =  1.),\n",
    "])\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "train_dataset = DatasetGenerator(metadata=metadata.loc[train_index, :],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=train_transform)\n",
    "\n",
    "valid_dataset = DatasetGenerator(metadata=metadata.loc[validation_index, :],\n",
    "                                 label_map=label_map,\n",
    "                                 selected_channels=selected_channels,\n",
    "                                 scaling_factor=scaling_factor,\n",
    "                                 reshape_size=reshape_size,\n",
    "                                 transform=validation_transform)\n",
    "\n",
    "# Convert to FastAI DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map = {\n",
    "     \"Ch1\": (\"Greys\", \"BF\"),  \n",
    "     \"Ch2\": (\"Greens\", \"Antibody\"),\n",
    "     \"Ch3\": (\"Reds\", \"CD18\"),\n",
    "     \"Ch4\": (\"Oranges\", \"F-Actin\"),\n",
    "     \"Ch6\": (\"RdPu\", \"MHCII\"),\n",
    "     \"Ch7\": (\"Purples\", \"CD3/CD4\"),\n",
    "     \"Ch11\": (\"Blues\", \"P-CD3zeta\"),\n",
    "     \"Ch12\": (\"Greens\", \"Live-Dead\")\n",
    " }\n",
    "\n",
    "save_multichannel_preview(train_dl, n_samples=10, save_path=\"train_multichannel_preview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([     4,     36,    105,    203,    245,    288,    300,    350,\\n               436,    446,\\n            ...\\n            424050, 424118, 424306, 424541, 424700, 424703, 424714, 424740,\\n            425025, 425063],\\n           dtype='int64', length=2923)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m metadata_exp1 \u001b[38;5;241m=\u001b[39m metadata[metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment 1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create dataset and DataLoader for Experiment 1\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_dataset_exp1 \u001b[38;5;241m=\u001b[39m DatasetGenerator(metadata\u001b[38;5;241m=\u001b[39m\u001b[43mmetadata_exp1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      5\u001b[0m                                       label_map\u001b[38;5;241m=\u001b[39mlabel_map,\n\u001b[1;32m      6\u001b[0m                                       selected_channels\u001b[38;5;241m=\u001b[39mselected_channels,\n\u001b[1;32m      7\u001b[0m                                       scaling_factor\u001b[38;5;241m=\u001b[39mscaling_factor,\n\u001b[1;32m      8\u001b[0m                                       reshape_size\u001b[38;5;241m=\u001b[39mreshape_size,\n\u001b[1;32m      9\u001b[0m                                       transform\u001b[38;5;241m=\u001b[39mtrain_transform)\n\u001b[1;32m     11\u001b[0m train_loader_exp1 \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset_exp1, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Preview a batch for Experiment 1\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/image_flow_cytometry_fine_tune/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([     4,     36,    105,    203,    245,    288,    300,    350,\\n               436,    446,\\n            ...\\n            424050, 424118, 424306, 424541, 424700, 424703, 424714, 424740,\\n            425025, 425063],\\n           dtype='int64', length=2923)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "metadata_exp1 = metadata[metadata['experiment'] == \"Experiment 1\"]\n",
    "\n",
    "# Create dataset and DataLoader for Experiment 1\n",
    "train_dataset_exp1 = DatasetGenerator(metadata=metadata_exp1.loc[train_index, :],\n",
    "                                      label_map=label_map,\n",
    "                                      selected_channels=selected_channels,\n",
    "                                      scaling_factor=scaling_factor,\n",
    "                                      reshape_size=reshape_size,\n",
    "                                      transform=train_transform)\n",
    "\n",
    "train_loader_exp1 = DataLoader(train_dataset_exp1, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# Preview a batch for Experiment 1\n",
    "save_multichannel_preview(train_loader_exp1, title=\"Experiment 1 - Batch Preview\")\n",
    "\n",
    "# Filter metadata for Experiment 2\n",
    "metadata_exp2 = metadata[metadata['experiment'] == \"Experiment 2\"]\n",
    "\n",
    "# Create dataset and DataLoader for Experiment 2\n",
    "train_dataset_exp2 = DatasetGenerator(metadata=metadata_exp2.loc[train_index, :],\n",
    "                                      label_map=label_map,\n",
    "                                      selected_channels=selected_channels,\n",
    "                                      scaling_factor=scaling_factor,\n",
    "                                      reshape_size=reshape_size,\n",
    "                                      transform=train_transform)\n",
    "\n",
    "train_loader_exp2 = DataLoader(train_dataset_exp2, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# Preview a batch for Experiment 2\n",
    "save_multichannel_preview(train_loader_exp2, title=\"Experiment 2 - Batch Preview\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
